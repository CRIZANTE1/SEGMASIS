# ü§ñ Sistema RITM (Retrieval-Inference-Text Merge)

## 1. O Que √© RITM e Por Que Usamos?

**RITM (Retrieval-Inference-Text Merge)** √© uma t√©cnica avan√ßada de IA que aprimora a capacidade de um Grande Modelo de Linguagem (LLM), como o Gemini, de responder a perguntas.

-   **Problema:** Um LLM padr√£o, mesmo que poderoso, possui um conhecimento "congelado" no tempo (sua data de treinamento) e pode n√£o ter acesso a informa√ß√µes muito espec√≠ficas, como os detalhes exatos de uma Norma Regulamentadora (NR) brasileira. Isso pode levar a respostas gen√©ricas ou imprecisas ("alucina√ß√µes").

-   **Solu√ß√£o RITM:** Em vez de apenas perguntar ao modelo, o sistema RITM primeiro **busca (Retrieval)** informa√ß√µes relevantes em uma base de conhecimento privada e confi√°vel. Em seguida, ele realiza **infer√™ncia (Inference)** sobre o contexto encontrado, e finalmente executa a **mesclagem de texto (Text Merge)** para gerar uma resposta coerente.

No SEGMA-SIS, o RITM √© a tecnologia que transforma o Gemini Pro de um modelo gen√©rico em um **especialista em auditoria de SST**, capaz de citar itens normativos espec√≠ficos ao analisar um documento.

## 2. Componentes do Sistema RITM

O nosso sistema RITM, implementado em `analysis/nr_analyzer.py`, √© composto por dois elementos principais que s√£o pr√©-processados e carregados na mem√≥ria.

#### `ritm_dataframe.pkl`
-   **O que √©:** Um arquivo [Pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) serializado (salvo em disco) que cont√©m a base de conhecimento textual.
-   **Estrutura:** Cada linha representa um "chunk" (peda√ßo) de texto de uma NR.
    -   `Source`: O nome do documento original (ex: "NR-01.pdf").
    -   `Answer_Chunk`: O texto do peda√ßo da norma.
    -   Outros metadados.
-   **Como foi criado:** Documentos PDF das principais NRs foram divididos em peda√ßos de texto l√≥gicos e sobrepostos para n√£o perder o contexto entre eles.

#### `ritm_embeddings.npy`
-   **O que √©:** Um arquivo NumPy array contendo os "embeddings" (vetores num√©ricos) de cada `Answer_Chunk` do dataframe.
-   **O que s√£o Embeddings:** S√£o representa√ß√µes matem√°ticas do significado sem√¢ntico de um texto. Textos com significados semelhantes ter√£o vetores numericamente pr√≥ximos no espa√ßo multidimensional.
-   **Como foi criado:** Cada `Answer_Chunk` foi processado pelo modelo de embedding do Google (`models/text-embedding-004`), que converteu o texto em um vetor de alta dimens√£o (ex: 768 n√∫meros). Este array tem a mesma quantidade de linhas que o `ritm_dataframe.pkl`.

## 3. Fluxo de Funcionamento da Busca Sem√¢ntica

Quando uma auditoria √© solicitada (ex: `perform_initial_audit` em `nr_analyzer.py`), o seguinte fluxo ocorre:

```mermaid
graph TD
    A[Consulta do Usu√°rio] --> B{_find_semantically_relevant_chunks};
    B --> C[1. Gerar Embedding da Consulta];
    C --> D{2. Calcular Similaridade de Cossenos};
    D -- Vetor da Consulta --> E[C√°lculo];
    F[ritm_embeddings.npy] -- Vetores da Base --> E;
    E --> G[3. Obter Top-K √çndices];
    G --> H{4. Recuperar Chunks do DataFrame};
    I[ritm_dataframe.pkl] -- DataFrame --> H;
    H --> J[5. Retornar Chunks Relevantes];
    J --> K[Contexto para o Prompt do Gemini];

    subgraph "Modelo de Embedding (Google)"
        C
    end
    subgraph "C√°lculo (Scikit-learn)"
        E
    end
    subgraph "Mem√≥ria da Aplica√ß√£o"
        I
        F
    end
```

## 4. Otimiza√ß√£o e Cache

- **Pr√©-processamento:** A gera√ß√£o dos embeddings da base de conhecimento √© um processo lento e caro. Por isso, ele √© feito offline e os resultados (ritm_embeddings.npy) s√£o salvos para serem apenas carregados pela aplica√ß√£o.
- **Cache em Mem√≥ria:** Os arquivos ritm_dataframe.pkl e ritm_embeddings.npy s√£o carregados na mem√≥ria apenas uma vez quando a aplica√ß√£o inicia, e s√£o mantidos em cache (@st.cache_data(ttl=3600)) para evitar leituras repetidas do disco.
